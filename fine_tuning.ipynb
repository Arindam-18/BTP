{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOAntou1NPlKHYZ3vO1oTxd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arindam-18/BTP/blob/main/fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "uoc_rhOBgJT5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "from transformers import BertModel, BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert = BertModel.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-UBdIbehNId",
        "outputId": "743ee995-f217-4d90-e376-9e492a73460c"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"sample_sarcasm.csv\")\n",
        "text = df.iloc[:, 1]\n",
        "split = round(len(df) * 0.75)\n",
        "train_text = df.iloc[:split, 1]\n",
        "train_labels = df.iloc[:split, 0]\n",
        "val_text = df.iloc[split:, 1]\n",
        "val_labels = df.iloc[split:, 0]\n",
        "\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "qoof6rq9hO9R"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, line in enumerate(text):\n",
        "    for val in tokenizer.encode(line):\n",
        "        if val == 100:\n",
        "            print(idx, line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNsDENlUoQHa",
        "outputId": "f35bc7e0-7095-45f7-b7bf-0afd1a1ad5ca"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149 ye dekho \" time \" [UNK] ke pass bhi de rukne ka hai time ke nahi ga hai\n",
            "419 sirf te sach bolne se hee khushiya milti je hoti... [UNK] to ko aaj re yu jhooth re ka khula do bazaar ka na laga ke hota! [UNK] rn\n",
            "419 sirf te sach bolne se hee khushiya milti je hoti... [UNK] to ko aaj re yu jhooth re ka khula do bazaar ka na laga ke hota! [UNK] rn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = [len(i.split()) for i in text]\n",
        "max_seq_len = max(seq_len)"
      ],
      "metadata": {
        "id": "h8Mg-sKxiQJV"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length=max_seq_len,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False,\n",
        ")\n",
        "\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length=max_seq_len,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False,\n",
        ")"
      ],
      "metadata": {
        "id": "46SLNIa8iTXX"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_seq = torch.tensor(tokens_train[\"input_ids\"])\n",
        "train_mask = torch.tensor(tokens_train[\"attention_mask\"])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val[\"input_ids\"])\n",
        "val_mask = torch.tensor(tokens_val[\"attention_mask\"])\n",
        "val_y = torch.tensor(val_labels.tolist())"
      ],
      "metadata": {
        "id": "Ttkol7I5iXom"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "a-kvHBefiZCH"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in bert.embeddings.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in bert.encoder.layer[:-1].parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "63S0Pm5Yibl-"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, bert):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(768, 512)\n",
        "        self.fc2 = nn.Linear(512, 2)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "        a = self.bert(sent_id, attention_mask=mask)\n",
        "        x = self.fc1(a[1])\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "IqUlwoNxkrRc"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier(bert)\n",
        "model = model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)\n",
        "cross_entropy  = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "2n7CUnxUktsO"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    total_preds = []\n",
        "    total_labels = []\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = [r.to(device) for r in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        preds = model(sent_id, mask)\n",
        "\n",
        "        loss = cross_entropy(preds, labels)\n",
        "        total_loss = total_loss + loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "        total_preds += list(preds)\n",
        "        total_labels += labels.tolist()\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "_bvBioiIkwfV"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate():\n",
        "    model.eval()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    total_preds = []\n",
        "    total_labels = []\n",
        "    for step, batch in enumerate(val_dataloader):\n",
        "        batch = [t.to(device) for t in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model(sent_id, mask)\n",
        "\n",
        "            loss = cross_entropy(preds, labels)\n",
        "            total_loss = total_loss + loss.item()\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "            preds = np.argmax(preds, axis=1)\n",
        "            total_preds += list(preds)\n",
        "            total_labels += labels.tolist()\n",
        "\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "2R4UphY4kyny"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(filename, epoch, model, optimizer):\n",
        "    state = {\"epoch\": epoch, \"model\": model, \"optimizer\": optimizer}\n",
        "    torch.save(state, filename)"
      ],
      "metadata": {
        "id": "xeUj3TZmk-9f"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float(\"inf\")\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(10):\n",
        "    print(f\"Epoch {epoch+1} / 10\")\n",
        "\n",
        "    train_loss = train()\n",
        "\n",
        "    valid_loss = evaluate()\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        file_name = \"topic_saved_weights.pt\"\n",
        "        save_checkpoint(file_name, epoch, model, optimizer)\n",
        "\n",
        "    print(f\"Training Loss: {train_loss}, Valid Loss: {valid_loss}\\n\")\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bvex71Qhn0wm",
        "outputId": "b5c2a18e-5f82-473d-b1b9-5cdc37be7028"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 10\n",
            "Training Loss: 0.6379268492261568, Valid Loss: 0.5078463368117809\n",
            "\n",
            "Epoch 2 / 10\n",
            "Training Loss: 0.49728407214085263, Valid Loss: 0.4848673795349896\n",
            "\n",
            "Epoch 3 / 10\n",
            "Training Loss: 0.2856728592887521, Valid Loss: 0.2675292487256229\n",
            "\n",
            "Epoch 4 / 10\n",
            "Training Loss: 0.23899089853512123, Valid Loss: 0.22390633239410818\n",
            "\n",
            "Epoch 5 / 10\n",
            "Training Loss: 0.2240685204936502, Valid Loss: 0.2767823599278927\n",
            "\n",
            "Epoch 6 / 10\n",
            "Training Loss: 0.22050062665948644, Valid Loss: 0.2687266189022921\n",
            "\n",
            "Epoch 7 / 10\n",
            "Training Loss: 0.24834125473474464, Valid Loss: 0.6054662950336933\n",
            "\n",
            "Epoch 8 / 10\n",
            "Training Loss: 0.3014853917993605, Valid Loss: 0.30188866844400764\n",
            "\n",
            "Epoch 9 / 10\n",
            "Training Loss: 0.2270571345773836, Valid Loss: 0.5126816757256165\n",
            "\n",
            "Epoch 10 / 10\n",
            "Training Loss: 0.18658980411904244, Valid Loss: 0.36544649582356215\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"topic_saved_weights.pt\"\n",
        "\n",
        "checkpoint = torch.load(path, map_location=device)\n",
        "model = checkpoint.get(\"model\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = model(val_seq.to(device), val_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "\n",
        "preds = np.argmax(preds, axis=1)\n",
        "\n",
        "sum = 0\n",
        "for x, y in zip(val_y, preds):\n",
        "    sum += x == y\n",
        "\n",
        "print((sum * 100 / len(val_y)).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsqJjxsMoDn5",
        "outputId": "2d490063-efbb-430f-f427-13c564f69924"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91.19999694824219\n"
          ]
        }
      ]
    }
  ]
}